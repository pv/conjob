#!/usr/bin/env python2.5
# -*-python-*-
"""
conjob [options] command [...]

Process job controller, letting a limited number of jobs run at the same
time.

commands:
  list                List scheduled PIDs
  schedule            Perfom scheduling, starting/stopping processes
  setprio JIDS PRIO   Set a priority for a PID
  run CMD             Run a command and put the process in the queue
  bg CMD              Run a command in the background and insert to queue
                      Redirect the output to a file in ~/.conjob.log/
  kill JIDS           Kill jobs
  tail JIDS           Tail -f logfiles
  less JIDS           Page through logfiles
  cleanup JIDS        Remove completed jobs from the job list
  requeue JIDS        Kill and re-queue given jobs

'JIDS' can be a comma separated list of JIDs, or a shell glob pattern.
The syntax '{MIN-MAX}' matches all integers from MIN to MAX.
Prepending '%' to the pattern makes it match also completed jobs.

"""
import os, sys, time, optparse, signal, tempfile, shutil, glob, re, fnmatch
import datetime, subprocess
import configobj

CFGFILE = os.path.expanduser("~/.conjob")

class Job(object):
    """
    Representation of a pending or running job.

    """
    date_format = '%Y-%m-%d %H:%M:%S'

    def __init__(self, jid, cmd, log_file):
        self.jid = jid
        self.process = None
        self.cmd = cmd
        self.log_file = log_file
        self.end_time = None
        self.queue_time = datetime.datetime.now()
        self.start_time = None
        self.priority = 0.

    @classmethod
    def _strptime(cls, s):
        return datetime.datetime.strptime(s, cls.date_format)

    @classmethod
    def from_section(cls, section):
        self = Job(None, None, None)
        self.jid = str(section['jid'])
        pid = section.get('pid', None)
        if pid is not None:
            self.process = Process(int(pid))
            if not self.process.is_alive:
                self.process = None
        self.cmd = section['cmd']
        self.log_file = section['log_file']
        if 'end_time' in section:
            self.end_time = cls._strptime(section['end_time'])
        if 'start_time' in section:
            self.start_time = cls._strptime(section['start_time'])
        self.queue_time = cls._strptime(section['queue_time'])
        self.priority = float(section.get('priority', 0.))
        return self

    def as_section(self):
        section = {}
        section['jid'] = self.jid
        if self.process is not None and self.process.is_alive:
            section['pid'] = self.process.pid
        if self.start_time is not None:
            section['start_time'] = self.start_time
        section['cmd'] = self.cmd
        section['log_file'] = self.log_file
        if self.end_time:
            section['end_time'] = self.end_time.strftime(self.date_format)
        if self.start_time:
            section['start_time'] = self.start_time.strftime(self.date_format)
        section['queue_time'] = self.queue_time.strftime(self.date_format)
        section['priority'] = self.priority
        return section

    def kill(self, signal=None):
        if self.process and self.process.is_alive:
            self.process.kill(signal)
            self.process.resume()
        if self.end_time is None:
            self.end_time = datetime.datetime.now()

    def reset(self):
        self.start_time = None
        self.end_time = None

    def resume(self):
        if self.is_alive:
            self.process.resume()

    def suspend(self):
        if self.is_alive:
            self.process.suspend()

    def set_cpu_affinity(self, cpu):
        if self.is_alive:
            self.process.set_cpu_affinity(cpu)

    def run(self, nice=None, ioprio=None):
        if self.completed:
            return
        if self.process:
            if not self.process.is_running:
                self.process.resume()
            return

        self.start_time = datetime.datetime.now()

        self.process = Process.fork_to_background(self.cmd, self.log_file,
                                                  ioprio=ioprio, nice=nice,
                                                  msg="Job %s" % self.jid)

    @property
    def is_alive(self):
        self._update_alive_state()
        return (self.process is not None)

    def _update_alive_state(self):
        if self.process and not self.process.is_alive:
            self.process = None

    @property
    def is_running(self):
        if self.process is None:
            return False
        return self.process.is_running

    @property
    def completed(self):
        return (self.end_time is not None)

    @property
    def started(self):
        return (self.start_time is not None)

    @property
    def pid(self):
        if not self.process:
            return None
        return self.process.pid

    def __repr__(self):
        return "<Job %s: %s>" % (self.jid, " ".join(self.cmd))


class PidScheduler(object):
    def __init__(self, filename):
        self.jobs = []
        self.cfg = configobj.ConfigObj(filename)
        self.cfg.setdefault('logdir', filename + '.log')
        self.cfg.setdefault('joblist', filename + '.jobs')
        self.cfg.setdefault('nprocs', 2)
        self.cfg.setdefault('nice', 10)
        self.cfg.setdefault('ioprio', 7)
        self.cfg.setdefault('loadavg', 2)
        self.cfg.setdefault('max_mem_percentage', 75)
        self.cfg['nice'] = int(self.cfg['nice'])
        self.cfg['ioprio'] = int(self.cfg['ioprio'])
        self.cfg['nprocs'] = int(self.cfg['nprocs'])
        self.cfg['loadavg'] = float(self.cfg['loadavg'])
        self.cfg['pidlist'] = str(self.cfg['pidlist'])
        self.cfg['logdir'] = str(self.cfg['logdir'])
        self.cfg['max_mem_percentage'] = float(self.cfg['max_mem_percentage'])
        self.load_jobs()

        if not os.path.isdir(self.cfg['logdir']):
            os.makedirs(self.cfg['logdir'])

    def load_jobs(self):
        cfg = configobj.ConfigObj(self.cfg['joblist'])
        for key, value in cfg.iteritems():
            self.jobs.append(Job.from_section(value))

    def save_jobs(self):
        # avoid write races by writing to a temp file and overwriting
        # by moving (which probably is atomic within a FS)
        fd, tmp_fn = tempfile.mkstemp(
                prefix=os.path.basename(self.cfg['joblist']),
                dir=os.path.dirname(self.cfg['joblist']))
        cfg = configobj.ConfigObj()
        cfg.filename = tmp_fn
        for job in self.jobs:
            cfg[job.jid] = job.as_section()
        cfg.write()
        shutil.move(tmp_fn, self.cfg['joblist'])

    def get_free_jid(self, prefix=""):
        if prefix:
            prefix = prefix + "-"
        else:
            prefix = ""
        def int_prefix(s):
            if not prefix:
                try: return int(s)
                except ValueError: return None
            else:
                if not s.startswith(prefix + '-'): return None
                try: return int(s[len(prefix)+1:])
                except ValueError: return None
        imax = max([int_prefix(job.jid) for job in self.jobs
                    if int_prefix(job.jid) is not None] + [0])
        return "%s%d" % (prefix, imax+1)

    def get_logfile_name(self, jid, timestamp=None):
        if timestamp is None:
            timestamp = time.strftime('%Y-%m-%d_%H-%M-%S')
        logfile_fn = os.path.join(self.cfg['logdir'],
                                  '%s.%s' % (jid, timestamp))
        return logfile_fn

    def save(self):
        self.save_pids()

    def add(self, cmd, prefix=None, priority=0.):
        jid = self.get_free_jid(prefix)
        logfile = self.get_logfile_name(jid)
        job = Job(jid, cmd, logfile)
        job.priority = priority
        self.jobs.append(job)
        return job

    def add_fg_and_save(self, cmd, prefix=None, priority=0.):
        job = self.add(cmd, prefix=prefix, priority=priority)
        job.process = Process(os.getpid())
        job.start_time = datetime.datetime.now()
        self.save_jobs()
        Process.exec_cmd(cmd,
                         nice=self.cfg['nice'],
                         ioprio=self.cfg['ioprio'],
                         stop=True,
                         msg="Job %s" % job.jid)

    def kill(self, job):
        job.kill()
        self.jobs.remove(job)

    def _update(self):
        for job in self.jobs:
            if job.start_time and not job.is_alive:
                job.end_time = datetime.datetime.now()

    def schedule(self):
        def _cmp_prio(a, b):
            return cmp(a.priority, b.priority)

        # Check status
        self._update()

        # Sort
        queue = [x for x in self.jobs if not x.completed]
        queue.sort(_cmp_prio, reverse=True)
        nprocs = self.cfg['nprocs']

        # Adjust according to load average
        running = len([z for z in queue if z.is_alive])
        max_nprocs = running + int(round(self.cfg['loadavg']
                                         - Process.get_loadavg()))
        max_nprocs = max(1, max_nprocs)
        nprocs = min(nprocs, max_nprocs)

        # Adjust according to memory usage
        total_mem = Process.get_total_mem()
        mem_max = total_mem * self.cfg['max_mem_percentage'] / 100.
        for j, job in enumerate(queue[:nprocs]):
            if job.is_alive:
                mem_max -= job.process.mem_used
            else:
                mem_max -= 0.05 * total_mem
            if mem_max < 0 and j > 0:
                nprocs = j
                break

        # Stop / continue
        to_run = queue[:nprocs]
        to_stop = queue[nprocs:]

        resumed = False

        for cpu, job in enumerate(to_run):
            if not job.is_running and not resumed:
                # only resume one job per schedule cycle
                job.run(nice=self.cfg['nice'], ioprio=self.cfg['ioprio'])
                resumed = True
            job.set_cpu_affinity(cpu)

        for job in to_stop:
            job.suspend()

        self._update()
        self.save_jobs()

    def jobs_iter(self, listspec, only_pending=True):
        if isinstance(listspec, str) and listspec.startswith('%'):
            listspec = listspec[1:]
            if not listspec:
                listspec = 'all'
            only_pending = False

        if not isinstance(listspec, str):
            for item in listspec:
                for job in self.jobs_iter(item, only_pending):
                    yield job
        elif listspec == 'all':
            for job in self.jobs:
                if not only_pending or not job.completed:
                    yield job
        elif ',' in listspec:
            items = [x.strip() for x in listspec.split(',')]
            for job in self.jobs_iter(items, only_pending):
                yield job
        elif '{' in listspec:
            pat = re.compile(r'{(\d+)-(\d+)}')
            ms = list(pat.finditer(listspec))
            if not ms:
                return
            limits = [(int(m.group(1)), int(m.group(2))) for m in ms]

            offset = 0
            spec2 = listspec
            for k, m in enumerate(ms):
                rep = '<<INDEX>>'
                spec2 = spec2[:offset+m.start()] + rep + spec2[offset+m.end():]
                offset += len(rep) - (m.end() - m.start())

            pat = "^" + fnmatch.translate(spec2)
            pat = pat.replace(r'\<\<INDEX\>\>', '(\d+)')
            pat = re.compile(pat)

            for job in self.jobs:
                jm = pat.match(job.jid)
                if jm:
                    ints = map(int, jm.groups())
                    ok = True
                    for k, (min, max) in zip(ints, limits):
                        if not min <= k <= max:
                            ok = False
                            break
                    if ok:
                        yield job
        else:
            for job in self.jobs:
                if fnmatch.fnmatch(job.jid, listspec):
                    if (not only_pending or not job.completed
                        or listspec == job.jid):
                        yield job

def do_schedule(sched, p):
    sched.schedule()

def do_setprio(sched, p):
    try:
        prio = float(p.args[1])
    except ValueError:
        p.error("Invalid priority")

    for job in sched.jobs_iter(p.args[0]):
        job.priority = prio

    sched.save_jobs()

def do_list(sched, p):
    if not p.args:
        p.args = ['all']

    for job in sched.jobs_iter(p.args):
        if job.is_running:
            mark = "* %d" % job.process.pid
        elif job.is_alive:
            mark = "- %d"  % job.process.pid
        elif job.started and not job.completed and not job.is_alive:
            mark = "/"
        else:
            mark = " "
            
        cmdline = ' '.join(job.cmd)
        try:
            print "%8s%-8s  %.2g  %s" % (job.jid, mark, job.priority, cmdline)
        except IOError:
            return

def do_kill(sched, p):
    watch = KillWatch(nprocs=(1+sched.cfg['nprocs']//2))
    for job in sched.jobs_iter(p.args):
        watch.kill(job)
    watch.flush()
    sched.save_jobs()

def do_requeue(sched, p):
    watch = KillWatch(nprocs=(1+sched.cfg['nprocs']//2))
    for job in sched.jobs_iter(p.args):
        watch.kill(job)
        job.reset()
    watch.flush()
    sched.save_jobs()

def do_tail(sched, p, base_cmd=['tail', '-f']):
    jobs = list(sched.jobs_iter(p.args))

    files = []
    for job in jobs:
        if os.path.isfile(job.log_file):
            files.append(job.log_file)

    if not files:
        print "No files to tail"
        return

    cmd = base_cmd + files
    os.execvp(cmd[0], cmd)

def do_less(sched, p):
    do_tail(sched, p, ['less', '+k'])

def do_run(sched, p):
    sched.add_fg_and_save(p.args,
                          prefix=p.options.prefix, priority=p.options.priority)
    # doesn't return

def do_run_bg(sched, p):
    sched.add(p.args,
              prefix=p.options.prefix, priority=p.options.priority)
    sched.save_jobs()

def do_cleanup(sched, p):
    if not p.args:
        p.args = ['all']
    to_remove = [x for x in sched.jobs_iter(p.args, only_pending=False)
                 if x.completed]
    for job in to_remove:
        sched.kill(job)
    sched.save_jobs()

def main(argv):
    p = optparse.OptionParser(__doc__.strip())
    p.add_option('-p', '--priority', action='store', type=str,
                 dest='priority', default=0,
                 help="Priority for the started process")
    p.add_option('-n', '--name-prefix', action='store', type=str,
                 dest='prefix', default=None,
                 help="Prefix for the JIDs of the jobs")
    p.allow_interspersed_args = False
    (options, args) = p.parse_args(argv)

    if len(args) < 1:
        p.error("No command given")

    sched = PidScheduler(CFGFILE)

    cmds = dict(schedule=do_schedule,
                setprio=do_setprio,
                list=do_list,
                ls=do_list,
                run=do_run,
                bg=do_run_bg,
                tail=do_tail,
                less=do_less,
                kill=do_kill,
                cleanup=do_cleanup,
                requeue=do_requeue)

    cmd = args.pop(0)
    func = cmds.get(cmd)

    p.args = args
    p.options = options
    if func is None:
        p.error("Unknown command %s" % cmd)
    else:
        func(sched, p)

#------------------------------------------------------------------------------
# Controlling processes
#------------------------------------------------------------------------------

class Process(object):
    def __init__(self, pid):
        self.pid = pid

    def kill(self, sig=None):
        if sig is None:
            sig = signal.SIGTERM
        os.kill(self.pid, sig)

    def suspend(self):
        os.kill(self.pid, signal.SIGSTOP)

    def resume(self):
        os.kill(self.pid, signal.SIGCONT)

    @property
    def mem_used(self):
        dr = '/proc/%d' % self.pid
        if os.path.isdir(dr):
            f = open('%s/status' % dr)
            try:
                lines = f.read().split("\n")
                for line in lines:
                    m = re.match(r'^VmSize:\s*(\d+) kB$', line)
                    if m:
                        return float(m.group(1))
            finally:
                f.close()
        return 0

    @property
    def is_running(self):
        dr = '/proc/%d' % self.pid
        if os.path.isdir(dr):
            f = open('%s/stat' % dr)
            try:
                x = f.read().split()
                return (x[2] != 'T')
            finally:
                f.close()
        else:
            return False

    @property
    def is_alive(self):
        return os.path.isdir('/proc/%d' % self.pid)

    def set_ioprio(self, ioprio=0):
        """Set IO priority"""
        if self.is_alive:
            subprocess.call(['ionice', '-p', str(self.pid), '-n', str(ioprio)],
                            stdout=subprocess.PIPE, stderr=subprocess.PIPE)

    def set_cpu_affinity(self, cpu=0):
        if self.is_alive:
            subprocess.call(['schedtool', '-a', str(cpu), str(self.pid)],
                            stdout=subprocess.PIPE, stderr=subprocess.PIPE)

    @staticmethod
    def get_loadavg():
        f = open('/proc/loadavg', 'r')
        try:
            data = f.read()
            return float(data.split()[0])
        finally:
            f.close()

    @staticmethod
    def get_ncpus():
        f = open('/proc/cpuinfo', 'r')
        try:
            ncpus = 0
            for line in f:
                if line.startswith('processor'):
                    ncpus += 1
            return ncpus
        finally:
            f.close()

    @staticmethod
    def get_total_mem():
        f = open('/proc/meminfo', 'r')
        try:
            lines = f.read().split("\n")
            for line in lines:
                m = re.match(r'^MemTotal:\s*(\d+) kB$', line)
                if m:
                    return float(m.group(1))
        finally:
            f.close()
        return 1e99

    @classmethod
    def fork_to_background(cls, cmd, logfile, nice=None, ioprio=None, msg=""):
        (pid_pipe_r, pid_pipe_w) = os.pipe()

        # 1st fork
        pid = os.fork()
        if pid > 0:
            # parent
            pid = int(os.read(pid_pipe_r, 64))
            os.close(pid_pipe_r)
            os.close(pid_pipe_w)
            return cls(pid)

        # invoke in background
        os.setsid()

        # 2nd fork to remove session leader status
        pid = os.fork()
        if pid > 0:
            # dummy parent
            sys.exit(0)

        self = cls(os.getpid())

        # deliver pid info to the parent
        os.write(pid_pipe_w, '%d\n' % self.pid)
        os.close(pid_pipe_r)
        os.close(pid_pipe_w)

        # redirect output + close input
        sys.stdout.flush()
        sys.stderr.flush()
        if isinstance(logfile, str):
            logfile = open(logfile, 'a')
        f = logfile
        f2 = open(os.devnull, 'r')
        os.dup2(f2.fileno(), sys.stdin.fileno())
        os.dup2(f.fileno(), sys.stdout.fileno())
        os.dup2(f.fileno(), sys.stderr.fileno())

        # run
        cls.exec_cmd(cmd, nice=nice, ioprio=ioprio, stop=False, msg=msg)

    @classmethod
    def exec_cmd(cls, cmd, nice=None, ioprio=None, stop=False, msg=""):
        self = cls(os.getpid())

        # renice
        if nice is not None:
            os.nice(nice)
        if ioprio is not None:
            self.set_ioprio(ioprio)

        if stop:
            self.suspend()

        if msg:
            print msg
        print datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'),os.getcwd()
        print " ".join(cmd)
        print "-"*79
        sys.stdout.flush()
        sys.stderr.flush()
        os.execvp(cmd[0], cmd)
        raise RuntimeError("Failed to execute command '%s'" % cmd)

    def __repr__(self):
        return "<Process %d>" % self.pid

class KillWatch(object):
    def __init__(self, nprocs):
        self.queue = []
        self.nprocs = nprocs

    def mass_kill(self, processes):
        for process in processes:
            self.kill(process)

    def kill(self, process):
        process.kill()
        if not process.is_alive:
            return

        self.queue.append(process)
        process.resume()

        time.sleep(0.05)
        for process in list(self.queue):
            if not process.is_alive:
                self.queue.remove(process)

        if len(self.queue) > self.nprocs:
            self.flush()

    def flush(self):
        for k in xrange(100):
            alive = False
            for process in self.queue:
                if process.is_alive:
                    alive = True
                    break
            if not alive:
                break
            time.sleep(0.05)
        for process in self.queue:
            if process.is_alive:
                process.kill(signal.SIGKILL)
        del self.queue[:]


if __name__ == "__main__":
    main(sys.argv[1:])
